{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06fd6ad4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"d:\\python\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[39m\n\u001b[32m     37\u001b[39m _os.environ.setdefault(\u001b[33m\"\u001b[39m\u001b[33mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[39m\n\u001b[32m     86\u001b[39m     sys.setdlopenflags(_default_dlopen_flags)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     89\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback.format_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     90\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     91\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     92\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     93\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mIf you need help, create an issue \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     94\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     95\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mand include the entire stack trace above this error message.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Traceback (most recent call last):\n  File \"d:\\python\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b12b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "raw_csv_data = np.loadtxt('./Audiobooks_data.csv', delimiter=',')\n",
    "\n",
    "unscaled_inputs_all = raw_csv_data[:, 1:-1]\n",
    "targets_all = raw_csv_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb843b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_one_targets = int(np.sum(targets_all))\n",
    "\n",
    "zero_targets_counter = 0\n",
    "\n",
    "indices_to_remove = []\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i] == 0:\n",
    "        zero_targets_counter += 1\n",
    "        if zero_targets_counter > num_one_targets:\n",
    "            indices_to_remove.append(i)\n",
    "\n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis=0)\n",
    "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis=0)\n",
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d0673f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7262ba67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1788.0 3579 0.49958088851634536\n",
      "232.0 447 0.5190156599552572\n",
      "217.0 448 0.484375\n"
     ]
    }
   ],
   "source": [
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "train_samples_count = int(0.8*samples_count)\n",
    "validation_samples_count = int(0.1*samples_count)\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count+validation_samples_count:]\n",
    "\n",
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\n",
    "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\n",
    "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed068fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('train', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('valid', inputs=validation_inputs, targets=validation_targets)\n",
    "np.savez('test', inputs=test_inputs, targets=test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7139358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('train.npz')\n",
    "\n",
    "train_input = npz['inputs'].astype(np.float32)\n",
    "train_traget = npz['targets'].astype(np.float32)\n",
    "\n",
    "npz = np.load('valid.npz')\n",
    "valid_input = npz['inputs'].astype(np.float32)\n",
    "valid_target = npz['targets'].astype(np.float32)\n",
    "\n",
    "npz = np.load('test.npz')\n",
    "test_input = npz['inputs'].astype(np.float32)\n",
    "test_target = npz['targets'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae164a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax')    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "726fac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 1s - 34ms/step - accuracy: 0.4979 - loss: 0.7523 - val_accuracy: 0.6130 - val_loss: 0.6831\n",
      "Epoch 2/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.7279 - loss: 0.6273 - val_accuracy: 0.7830 - val_loss: 0.5980\n",
      "Epoch 3/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.8145 - loss: 0.5326 - val_accuracy: 0.8523 - val_loss: 0.4935\n",
      "Epoch 4/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.8497 - loss: 0.4381 - val_accuracy: 0.8747 - val_loss: 0.3967\n",
      "Epoch 5/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.8653 - loss: 0.3718 - val_accuracy: 0.8837 - val_loss: 0.3367\n",
      "Epoch 6/100\n",
      "36/36 - 0s - 5ms/step - accuracy: 0.8757 - loss: 0.3356 - val_accuracy: 0.8881 - val_loss: 0.3068\n",
      "Epoch 7/100\n",
      "36/36 - 0s - 5ms/step - accuracy: 0.8801 - loss: 0.3160 - val_accuracy: 0.8926 - val_loss: 0.2908\n",
      "Epoch 8/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.8854 - loss: 0.3028 - val_accuracy: 0.8971 - val_loss: 0.2823\n",
      "Epoch 9/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.8888 - loss: 0.2933 - val_accuracy: 0.8971 - val_loss: 0.2725\n",
      "Epoch 10/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.8913 - loss: 0.2849 - val_accuracy: 0.8949 - val_loss: 0.2718\n",
      "Epoch 11/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.8961 - loss: 0.2781 - val_accuracy: 0.8971 - val_loss: 0.2678\n",
      "Epoch 12/100\n",
      "36/36 - 0s - 3ms/step - accuracy: 0.8969 - loss: 0.2727 - val_accuracy: 0.8971 - val_loss: 0.2626\n",
      "Epoch 13/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.8997 - loss: 0.2685 - val_accuracy: 0.8993 - val_loss: 0.2618\n",
      "Epoch 14/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.8986 - loss: 0.2644 - val_accuracy: 0.8993 - val_loss: 0.2601\n",
      "Epoch 15/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9039 - loss: 0.2609 - val_accuracy: 0.9016 - val_loss: 0.2584\n",
      "Epoch 16/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9042 - loss: 0.2571 - val_accuracy: 0.9016 - val_loss: 0.2555\n",
      "Epoch 17/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9033 - loss: 0.2543 - val_accuracy: 0.9016 - val_loss: 0.2546\n",
      "Epoch 18/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9044 - loss: 0.2520 - val_accuracy: 0.9038 - val_loss: 0.2547\n",
      "Epoch 19/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9042 - loss: 0.2495 - val_accuracy: 0.9016 - val_loss: 0.2524\n",
      "Epoch 20/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9047 - loss: 0.2481 - val_accuracy: 0.9038 - val_loss: 0.2530\n",
      "Epoch 21/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9078 - loss: 0.2461 - val_accuracy: 0.9016 - val_loss: 0.2510\n",
      "Epoch 22/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9070 - loss: 0.2448 - val_accuracy: 0.9038 - val_loss: 0.2483\n",
      "Epoch 23/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9067 - loss: 0.2422 - val_accuracy: 0.9038 - val_loss: 0.2493\n",
      "Epoch 24/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9081 - loss: 0.2423 - val_accuracy: 0.9038 - val_loss: 0.2491\n",
      "Epoch 25/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9092 - loss: 0.2408 - val_accuracy: 0.9038 - val_loss: 0.2461\n",
      "Epoch 26/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9092 - loss: 0.2386 - val_accuracy: 0.9038 - val_loss: 0.2475\n",
      "Epoch 27/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9089 - loss: 0.2380 - val_accuracy: 0.9060 - val_loss: 0.2454\n",
      "Epoch 28/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9095 - loss: 0.2366 - val_accuracy: 0.9060 - val_loss: 0.2438\n",
      "Epoch 29/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9100 - loss: 0.2355 - val_accuracy: 0.9038 - val_loss: 0.2428\n",
      "Epoch 30/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9100 - loss: 0.2348 - val_accuracy: 0.9038 - val_loss: 0.2458\n",
      "Epoch 31/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9095 - loss: 0.2346 - val_accuracy: 0.9060 - val_loss: 0.2459\n",
      "Epoch 32/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9123 - loss: 0.2334 - val_accuracy: 0.9038 - val_loss: 0.2429\n",
      "Epoch 33/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9125 - loss: 0.2331 - val_accuracy: 0.9038 - val_loss: 0.2395\n",
      "Epoch 34/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9128 - loss: 0.2322 - val_accuracy: 0.9016 - val_loss: 0.2428\n",
      "Epoch 35/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9123 - loss: 0.2318 - val_accuracy: 0.9060 - val_loss: 0.2375\n",
      "Epoch 36/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9125 - loss: 0.2313 - val_accuracy: 0.9060 - val_loss: 0.2400\n",
      "Epoch 37/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9125 - loss: 0.2299 - val_accuracy: 0.9060 - val_loss: 0.2381\n",
      "Epoch 38/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9125 - loss: 0.2301 - val_accuracy: 0.9060 - val_loss: 0.2404\n",
      "Epoch 39/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9134 - loss: 0.2294 - val_accuracy: 0.9038 - val_loss: 0.2437\n",
      "Epoch 40/100\n",
      "36/36 - 0s - 4ms/step - accuracy: 0.9148 - loss: 0.2292 - val_accuracy: 0.9038 - val_loss: 0.2418\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21948606480>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "max_epochs = 100\n",
    "\n",
    "earlt_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(train_input,train_targets,\n",
    "          batch_size=batch_size,\n",
    "          epochs=max_epochs,\n",
    "          validation_data=(valid_input, valid_target),\n",
    "          callbacks=[earlt_stopping],\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a4bf913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9257 - loss: 0.2312 \n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy = model.evaluate(test_input, test_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
